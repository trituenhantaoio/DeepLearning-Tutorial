{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Autograd trong Pytorch - trituenhantao.io",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trituenhantaoio/DeepLearning-Tutorial/blob/master/Autograd_trong_Pytorch_trituenhantao_io.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP9Ytxok6TwJ"
      },
      "source": [
        "\n",
        "Autograd: Tự động tính vi phân\n",
        "===================================\n",
        "\n",
        "Cốt lõi của các mạng nơ ron trong PyTorch là gói ``autograd``.\n",
        "\n",
        "\n",
        "Gói ``autograd`` cung cấp phép tính vi phân tự động cho mọi phép toán trên Tensor. \n",
        "\n",
        "Trước tiên, hãy tìm hiểu một số thuật ngữ cần thiết.\n",
        "\n",
        "Tensor\n",
        "--------\n",
        "\n",
        "``torch.Tensor`` nếu thuộc tính\n",
        "``.requires_grad`` được đặt bằng ``True``, ``autograd`` sẽ theo dõi mọi phép toán thực hiện trên Tensor đó. Khi đã thực hiện xong, ta có thể gọi phương thức ``.backward()`` và các giá trị đạo hàm được tính một cách tự động. Giá trị này được tính cộng dồn vào thuộc tính ``.grad`` của Tensor.\n",
        "\n",
        "Để dừng theo dõi một Tensor, ta sử dụng ``.detach()`` để tách nó ra khỏi lịch sử tính toán và các phép toán sau này cũng không được theo dõi.\n",
        "\n",
        "Ngoài ra chúng ta cũng có thể sử dụng khối ``with torch.no_grad():``. Khối này hữu ích khi chúng ta đánh giá mô hình vì một mô hình có thể chứa các tham số với ``requires_grad=True``, nhưng khi đánh giá thì ta không quan tâm đến đạo hàm.\n",
        "\n",
        "Một lớp nữa rất quan trọng với ``autograd`` là ``Function`` (hàm).\n",
        "\n",
        "``Tensor`` và ``Function`` kết nối với nhau thành một đồ thị không có chu trình biểu diễn lịch sử tính toán. Mỗi ``Tensor`` có một thuộc tính ``.grad_fn`` trỏ đến một ``Function`` tạo ra nó (ngoại trừ các Tensor được tạo bởi người dùng, thuộc tính ``grad_fn`` của chúng là ``None``).\n",
        "\n",
        "Nếu muốn tính đạo hàm, ta có thể gọi ``.backward()`` trên một ``Tensor``. Nếu ``Tensor`` là kiểu số (scalar) (tức là nó chỉ chứa một phần tử), ta không cần chỉ định đối số cho ``backward()``. Nhưng nếu nó có nhiều hơn một phần tử, ta cần phải chỉ định rõ đối số cho ``gradient`` với định dạng phù hợp.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVQCHSdU6TwK"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG4L8qrX6TwT"
      },
      "source": [
        "Tạo một Tensor và đặt ``requires_grad=True`` để theo dõi các phép toán trên nó\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcixh3h6TwU",
        "outputId": "78f839e8-f159-4c29-e766-75499383c5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgW0Rl456TwX"
      },
      "source": [
        "Thực hiện phép toán:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taVmPp4u6TwY",
        "outputId": "77a00a47-77bd-4502-858c-3e68aea4cf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0VuVbld6Twb"
      },
      "source": [
        "``y`` được tạo từ kết quả của một phép toán nên nó có thuộc tính ``grad_fn``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQkcf-6u6Twc",
        "outputId": "033ef90c-c68f-48d3-95f4-8f552f45c8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7fc8e39e94e0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJFRNeTV6Twk"
      },
      "source": [
        "Thực hiện thêm phép toán trên ``y``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhgukn1X6Twk",
        "outputId": "819687e8-d192-4aec-a547-e7261cb2feed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_PltSvz6Two"
      },
      "source": [
        "``.requires_grad_( ... )`` thay đổi thuộc tính ``requires_grad`` của Tensor hiện tại. Thuộc tính này mặc định là ``False`` nếu không được chỉ định.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WyHCXjQ6Twp",
        "outputId": "44247505-3b97-4762-f196-63de5bae3b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7fc8992a2e10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpPgY9GR6Tww"
      },
      "source": [
        "Độ dốc (gradient)\n",
        "---------\n",
        "Ta tiến hành lan truyền ngược (backprop)\n",
        "Vì ``out`` chứa một giá trị scalar, ``out.backward()`` tương đương với ``out.backward(torch.tensor(1.))``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G7ZZYd56Twx"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FULNAczI6Tw0"
      },
      "source": [
        "In giá trị đạo hàm d(out)/dx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdefQaV6Tw1",
        "outputId": "edf6e738-c3be-40dc-8a40-57a13907088e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYfqQJCB6Tw4"
      },
      "source": [
        "Kết quả là một ma trận với các số ``4.5``. Gọi *Tensor* ``out``\n",
        "là “$o$”.\n",
        "Ta có $o = \\frac{1}{4}\\sum_i z_i$,\n",
        "$z_i = 3(x_i+2)^2$ và $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
        "Do đó,\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, và\n",
        "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSNF16LN6Tw5"
      },
      "source": [
        "Về mặt toán học, nếu ta có một hàm $\\vec{y}=f(\\vec{x})$,\n",
        "thì các giá trị đạo hàm của $\\vec{y}$ trên $\\vec{x}$\n",
        "là một ma trận Jacobi:\n",
        "\n",
        "\\begin{align}J=\\left(\\begin{array}{ccc}\n",
        "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
        "   \\vdots & \\ddots & \\vdots\\\\\n",
        "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "   \\end{array}\\right)\\end{align}\n",
        "\n",
        "Nói chung là, ``torch.autograd`` là công cụ để tính toán trên véc tơ và ma trận Jacobi. Tức là, với một véc tơ\n",
        "$v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$,\n",
        "nó sẽ tính được tích $v^{T}\\cdot J$. Nếu $v$ là độ dốc của một hàm scalar $l=g\\left(\\vec{y}\\right)$,\n",
        "tức là,\n",
        "$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$,\n",
        "thì theo quy tắc dây chuyền, tích của véc tơ và ma trận Jacobi sẽ là độ dốc của $l$ đối với $\\vec{x}$:\n",
        "\n",
        "\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
        "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
        "   \\vdots & \\ddots & \\vdots\\\\\n",
        "   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "   \\end{array}\\right)\\left(\\begin{array}{c}\n",
        "   \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
        "   \\vdots\\\\\n",
        "   \\frac{\\partial l}{\\partial y_{m}}\n",
        "   \\end{array}\\right)=\\left(\\begin{array}{c}\n",
        "   \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
        "   \\vdots\\\\\n",
        "   \\frac{\\partial l}{\\partial x_{n}}\n",
        "   \\end{array}\\right)\\end{align}\n",
        "\n",
        "(Lưu ý rằng $v^{T}\\cdot J$ cho một véc tơ hàng nhưng ta có thể có một véc tơ cột bằng cách lấy $J^{T}\\cdot v$.)\n",
        "\n",
        "Tính chất này của tích véc tơ Jacobi giúp thuận tiện hóa cho việc đưa độ dốc từ ngoài vào trong mô hình với đầu ra không phải dạng số.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsDqPYhH6Tw5"
      },
      "source": [
        "Dưới đây là một ví dụ về tích véc tơ Jacobi:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYV-XEHc6Tw6",
        "outputId": "1a583174-11bc-452b-bafc-b9513c74ff17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ -498.3744, -1358.6482,   331.9124], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYovZUQv6TxB"
      },
      "source": [
        "Trong trường hợp này ``y`` không phải scalar. ``torch.autograd`` không thể thực hiện phép toán Jacobi một cách trực tiếp, nhưng nếu chúng ta cần lấy tích véc tơ Jacobi, ta chỉ cần truyền véc tơ vào phương thức dưới dạng đối số của ``backward()`` :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VwLwCG96TxB",
        "outputId": "8a6f74fa-18a8-4bcd-e036-b959c8ba9a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcX38Tbx6TxF"
      },
      "source": [
        "Ta có thể dừng việc ``autograd`` theo dõi lịch sử tính toán của Tensor có ``requires_grad=True`` bằng cách gói đoạn code trong\n",
        "``with torch.no_grad():``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miMYFWBt6TxG",
        "outputId": "f0ad7381-4dcd-4dae-e6bc-c875991f2708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV_L4VdE6TxJ"
      },
      "source": [
        "Hoặc sử dụng ``.detach()`` để có được Tensor mới có cùng giá trị nhưng có ``requires_grad=False``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzhlTTXd6TxJ",
        "outputId": "a90e5587-11a6-4c00-f6fe-0425c3e63d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}